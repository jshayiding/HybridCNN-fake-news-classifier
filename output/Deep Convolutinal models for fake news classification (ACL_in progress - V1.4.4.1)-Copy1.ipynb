{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "import nlp_util\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Conv1D, Dense, Input, Lambda, LSTM\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing import sequence\n",
    "import _pickle as cPickle\n",
    "\n",
    "from keras.layers import Concatenate, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences # To make vectors the same size. \n",
    "# from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPool1D, MaxPool1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, CSVLogger, EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load dataset\n",
    "train_file=pd.read_csv('train.tsv', sep='\\t', header=None, encoding='utf-8')\n",
    "test_file=pd.read_csv('test.tsv', sep='\\t', header=None, encoding='utf-8')\n",
    "va_file=pd.read_csv('valid.tsv', sep='\\t', header=None, encoding='utf-8')\n",
    "\n",
    "column_names = ['Id', 'Label','Statement','Subject','Speaker','Speaker Job','State Info','Party','BT','FC','HT','MT','PF','Context']\n",
    "train_file.columns, test_file.columns, va_file.columns=column_names, column_names, column_names\n",
    "\n",
    "train_data = train_file[train_file.columns[~train_file.columns.isin(['Id','BT','FC','HT','MT','PF'])]]\n",
    "test_data = test_file[test_file.columns[~test_file.columns.isin(['Id','BT','FC','HT','MT','PF'])]]\n",
    "val_data = va_file[va_file.columns[~va_file.columns.isin(['Id','BT','FC','HT','MT','PF'])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_labels_dict = {'false':0, 'true':1,'pants-fire':2,'barely-true':3,'half-true':4,'mostly-true':5}\n",
    "binary_labels = {'false':1, 'true':-1,'pants-fire':1,'barely-true':1,'half-true':0,'mostly-true':-1}\n",
    "\n",
    "\n",
    "def one_hot_label(label):\n",
    "    return to_categorical(multi_labels_dict[x], num_classes=6)\n",
    "\n",
    "train_data['multi_label']=train_data['Label'].apply(lambda x: multi_labels_dict[x])\n",
    "test_data['multi_label']=test_data['Label'].apply(lambda x: multi_labels_dict[x])\n",
    "val_data['multi_label']=val_data['Label'].apply(lambda x: multi_labels_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers= ['barack-obama', 'donald-trump', 'hillary-clinton', 'mitt-romney', \n",
    "                'scott-walker', 'john-mccain', 'rick-perry', 'chain-email', \n",
    "                'marco-rubio', 'rick-scott', 'ted-cruz', 'bernie-s', 'chris-christie', \n",
    "                'facebook-posts', 'charlie-crist', 'newt-gingrich', 'jeb-bush', \n",
    "                'joe-biden', 'blog-posting','paul-ryan']\n",
    "\n",
    "speaker_dict={}\n",
    "for cnt, speaker in enumerate(speakers):\n",
    "    speaker_dict[speaker]=cnt\n",
    "print(speaker_dict)\n",
    "\n",
    "def speaker_projection(speaker):\n",
    "    if isinstance(speaker, str):\n",
    "        speaker=speaker.lower()\n",
    "        matched=[s for s in speakers if s in speaker]\n",
    "        if len(matched)>0:\n",
    "            return speaker_dict[matched[0]]\n",
    "        else:\n",
    "            return len(speakers)\n",
    "        \n",
    "##\n",
    "train_data['speaker_id']=train_data['Speaker'].apply(speaker_projection)\n",
    "test_data['speaker_id']=test_data['Speaker'].apply(speaker_projection)\n",
    "val_data['speaker_id']=val_data['Speaker'].apply(speaker_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map job\n",
    "job_list = ['president', 'u.s. senator', 'governor', 'president-elect', 'presidential candidate', \n",
    "                'u.s. representative', 'state senator', 'attorney', 'state representative', 'congress', 'others']\n",
    "\n",
    "\n",
    "job_dict = {'president':0, 'u.s. senator':1, 'governor':2, 'president-elect':3, 'presidential candidate':4, \n",
    "            'u.s. representative':5, 'state senator':6, 'attorney':7, 'state representative':8, 'congress':9, 'others':10}\n",
    "\n",
    "## Map job\n",
    "\n",
    "def job_projection(job):\n",
    "    if isinstance(job, str):\n",
    "        job=job.lower()\n",
    "        matched_job=[j for j in job_list if j in job]\n",
    "        if len(matched_job)>0:\n",
    "            return job_dict[matched_job[0]]\n",
    "        else:\n",
    "            return 10\n",
    "    else:\n",
    "        return 10\n",
    "\n",
    "## job projection output\n",
    "\n",
    "train_data['job_id']=train_data['Speaker Job'].apply(job_projection)\n",
    "test_data['job_id']=test_data['Speaker Job'].apply(job_projection)\n",
    "val_data['job_id']=val_data['Speaker Job'].apply(job_projection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Map political parties\n",
    "party_dict={'republican':0, 'democrat':1, 'none':2, 'organization':3, 'newsmaker':4, 'rest':5}\n",
    "\n",
    "def map_political_party(party):\n",
    "    if party in party_dict:\n",
    "        return party_dict[party]\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "##\n",
    "train_data['party_id']=train_data['Party'].apply(map_political_party)\n",
    "test_data['party_id']=test_data['Party'].apply(map_political_party)\n",
    "val_data['party_id']=val_data['Party'].apply(map_political_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map states\n",
    "all_states = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado',\n",
    "              'Connecticut','Delaware','Florida','Georgia','Hawaii','Idaho', \n",
    "              'Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana',\n",
    "              'Maine' 'Maryland','Massachusetts','Michigan','Minnesota',\n",
    "              'Mississippi', 'Missouri','Montana','Nebraska','Nevada',\n",
    "              'New Hampshire','New Jersey','New Mexico','New York',\n",
    "              'North Carolina','North Dakota','Ohio',    \n",
    "              'Oklahoma','Oregon','Pennsylvania','Rhode Island',\n",
    "              'South  Carolina','South Dakota','Tennessee','Texas','Utah',\n",
    "              'Vermont','Virginia','Washington','West Virginia',\n",
    "              'Wisconsin','Wyoming']\n",
    "\n",
    "\n",
    "states_dict = {'wyoming': 48, 'colorado': 5, 'washington': 45, 'hawaii': 10, \n",
    "               'tennessee': 40, 'wisconsin': 47, 'nevada': 26, 'north dakota': 32, \n",
    "               'mississippi': 22, 'south dakota': 39, 'new jersey': 28, 'oklahoma': 34, \n",
    "               'delaware': 7, 'minnesota': 21, 'north carolina': 31, 'illinois': 12, \n",
    "               'new york': 30, 'arkansas': 3, 'west virginia': 46, 'indiana': 13, \n",
    "               'louisiana': 17, 'idaho': 11, 'south  carolina': 38, 'arizona': 2, \n",
    "               'iowa': 14, 'mainemaryland': 18, 'michigan': 20, 'kansas': 15, \n",
    "               'utah': 42, 'virginia': 44, 'oregon': 35, 'connecticut': 6, 'montana': 24, \n",
    "               'california': 4, 'massachusetts': 19, 'rhode island': 37, 'vermont': 43, \n",
    "               'georgia': 9, 'pennsylvania': 36, 'florida': 8, 'alaska': 1, 'kentucky': 16,\n",
    "               'nebraska': 25, 'new hampshire': 27, 'texas': 41, 'missouri': 23, 'ohio': 33,\n",
    "               'alabama': 0, 'new mexico': 29, 'rest':50}\n",
    "\n",
    "\n",
    "def state_projection(state):\n",
    "    if isinstance(state, str):\n",
    "        state=state.lower()\n",
    "        if state in states_dict:\n",
    "            return states_dict[state]\n",
    "        else:\n",
    "            if 'washington' in state:\n",
    "                return states_dict['washington']\n",
    "            else:\n",
    "                return 50\n",
    "    else:\n",
    "        return 50\n",
    "    \n",
    "## state mapping output:\n",
    "train_data['state_id']=train_data['State Info'].apply(state_projection)\n",
    "test_data['state_id']=test_data['State Info'].apply(state_projection)\n",
    "val_data['state_id']=val_data['State Info'].apply(state_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## map subject\n",
    "subject_list = ['health','tax','immigration','election','education',\n",
    "    'candidates-biography','economy','gun','jobs','federal-budget','energy','abortion','foreign-policy']\n",
    "\n",
    "subject_dict = {'health':0,'tax':1,'immigration':2,'election':3,'education':4,\n",
    "                'candidates-biography':5,'economy':6,'gun':7,'jobs':8,'federal-budget':9,\n",
    "                'energy':10,'abortion':11,'foreign-policy':12, 'others':13}\n",
    "\n",
    "## mapping subject\n",
    "def subject_projection(subject):\n",
    "    if isinstance(subject, str):\n",
    "        subject=subject.lower()\n",
    "        matched_subject=[subj for subj in subject_list if subj in subject]\n",
    "        \n",
    "        if len(matched_subject)>0:\n",
    "            return subject_dict[matched_subject[0]]\n",
    "        else:\n",
    "            return 13\n",
    "    else:\n",
    "        return 13\n",
    "    \n",
    "##\n",
    "train_data['subject_id']=train_data['Subject'].apply(subject_projection)\n",
    "test_data['subject_id']=test_data['Subject'].apply(subject_projection)\n",
    "val_data['subject_id']=val_data['Subject'].apply(subject_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Context mapping\n",
    "Context_list = ['news release','interview','tv','radio',\n",
    "                'campaign','news conference','press conference','press release',\n",
    "                'tweet','facebook','email']\n",
    "\n",
    "Context_dict = {'news release':0,'interview':1,'tv':2,'radio':3,\n",
    "                'campaign':4,'news conference':5,'press conference':6,'press release':7,\n",
    "                'tweet':8,'facebook':9,'email':10, 'others':11}\n",
    "\n",
    "def Context_projection(context):\n",
    "    if isinstance(context, str):\n",
    "        context=context.lower()\n",
    "        matched_context=[cntx for cntx in Context_list if cntx in context]\n",
    "        if len(matched_context)>0:\n",
    "            return Context_dict[matched_context[0]]\n",
    "        else:\n",
    "            return 11\n",
    "    else:\n",
    "        return 11\n",
    "    \n",
    "## context projection output\n",
    "train_data['context_id']=train_data['Context'].apply(Context_projection)\n",
    "test_data['context_id']=test_data['Context'].apply(Context_projection)\n",
    "val_data['context_id']=val_data['Context'].apply(Context_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tokenize fake news statement and build vocabulary\n",
    "vocab_dict={}\n",
    "\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(train_data['Statement'])\n",
    "vocab_dict=tokenizer.word_index\n",
    "cPickle.dump(tokenizer.word_index, open(\"vocab.p\",\"wb\"))\n",
    "print(\"vocab dictionary is created\")\n",
    "print(\"saved vocan dictionary to pickle file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data preprocessing\n",
    "\n",
    "# def preprocessing_txt(dataset):\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     corpus=[]\n",
    "#     for elm in range(0, len(dataset.index)):\n",
    "#         res=' '.join([i for i in dataset['Statement'][elm].lower().split() if i not in stop_words])\n",
    "#         res=re.sub(\"</?.*?>\",\" <> \",dataset['Statement'][elm])    # remove tags\n",
    "#         res=re.sub(\"(\\\\d|\\\\W)+\",\" \",dataset['Statement'][elm])        # remove special characte\n",
    "#         res=re.sub(r'@([A-Za-z0-9_]+)', \"\",dataset['Statement'][elm])  # remove twitter handler\n",
    "#         res=re.sub('(\\r)+', \"\", dataset['Statement'][elm])            # remove newline character\n",
    "#         res=re.sub('[^\\x00-\\x7F]+', \"\", dataset['Statement'][elm])    # remove non-ascii characters\n",
    "#         res=''.join(x for x in dataset['Statement'][elm] if x not in set(string.punctuation))   ## remove punctuation\n",
    "#         corpus.append(res)\n",
    "#     return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(vocab_dict.keys())\n",
    "hidden_size = 100 #Has to be same as EMBEDDING_DIM\n",
    "lstm_size = 100\n",
    "num_steps = 64\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "#Hyperparams for CNN\n",
    "kernel_sizes = [2,3,5,7]\n",
    "filter_size = 128\n",
    "#Meta data related hyper params\n",
    "num_party = 6\n",
    "num_state = 51\n",
    "num_context = 12\n",
    "num_job = 11\n",
    "num_sub = 14\n",
    "num_speaker = 21\n",
    "embedding_dims=300\n",
    "max_features = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create embedding layer\n",
    "num_words=len(vocab_dict)+1\n",
    "\n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    embeddings_index = {}\n",
    "    f = open(gloveFile, encoding='utf8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-300])\n",
    "        coefs = np.asarray(values[-300:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index\n",
    "\n",
    "glove_model = loadGloveModel('glove.6B.300d.txt')\n",
    "\n",
    "def build_glove_embedding_layers():\n",
    "    embed_matrix=np.zeros((max_features, embedding_dims))\n",
    "    for word, indx in tokenizer.word_index.items():\n",
    "        if indx >= max_features:\n",
    "            continue\n",
    "        if word in glove_model:\n",
    "            embed_vec=glove_model[word]\n",
    "            if embed_vec is not None:\n",
    "                embed_matrix[indx]=embed_vec\n",
    "    return embed_matrix\n",
    "\n",
    "embedding_weights=build_glove_embedding_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data preprocessing\n",
    "def preprocessing_txt_keras(statement):\n",
    "    txt=text_to_word_sequence(statement)\n",
    "    val=[0]*20\n",
    "    val=[vocab_dict[t] for t in txt if t in vocab_dict]   ##replace unknown words with zero index\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training instances list\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "### remove stopwords fitst\n",
    "train_data['Statement'] = list(map(' '.join, train_data['Statement'].apply(lambda x: [item for item in x.lower().split() if item not in stop])))\n",
    "test_data['Statement'] = list(map(' '.join, test_data['Statement'].apply(lambda x: [item for item in x.lower().split() if item not in stop])))\n",
    "val_data['Statement'] = list(map(' '.join, val_data['Statement'].apply(lambda x: [item for item in x.lower().split() if item not in stop])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['word_id']=train_data['Statement'].apply(preprocessing_txt_keras)\n",
    "test_data['word_id']=test_data['Statement'].apply(preprocessing_txt_keras)\n",
    "val_data['word_id']=val_data['Statement'].apply(preprocessing_txt_keras)\n",
    "\n",
    "x_train=train_data['word_id']\n",
    "x_test=test_data['word_id']\n",
    "x_val=val_data['word_id']\n",
    "\n",
    "y_train=train_data['multi_label']\n",
    "y_val=val_data['multi_label']\n",
    "\n",
    "##\n",
    "x_train=sequence.pad_sequences(x_train, maxlen=num_steps, padding='post', truncating='post')\n",
    "y_train=to_categorical(y_train, num_classes=6)\n",
    "x_val=sequence.pad_sequences(x_val, maxlen=num_steps, padding='post', truncating='post')\n",
    "y_val=to_categorical(y_val, num_classes=6)\n",
    "x_test=sequence.pad_sequences(x_test, maxlen=num_steps, padding='post', truncating='post')\n",
    "\n",
    "## meta data preparation\n",
    "tr_party=to_categorical(train_data['party_id'], num_classes=num_party)\n",
    "tr_state=to_categorical(train_data['state_id'], num_classes=num_state)\n",
    "tr_cont=to_categorical(train_data['context_id'], num_classes=num_context)\n",
    "tr_job=to_categorical(train_data['job_id'], num_classes=num_job)\n",
    "tr_subj=to_categorical(train_data['subject_id'], num_classes=num_sub)\n",
    "# tr_speaker=to_categorical(train_data['speaker_id'], num_classes=num_speaker)\n",
    "\n",
    "# ## put all metadata of train data together in one stack\n",
    "# x_train_metadata=np.hstack(tr_party, tr_state, tr_job, tr_subj, tr_speaker, tr_cont)\n",
    "x_train_metadata=np.hstack((tr_party, tr_state, tr_cont,tr_job, tr_subj))\n",
    "\n",
    "\n",
    "# #********************************************************************************#\n",
    "val_party=to_categorical(val_data['party_id'], num_classes=num_party)\n",
    "val_state=to_categorical(val_data['state_id'], num_classes=num_state)\n",
    "val_cont=to_categorical(val_data['context_id'], num_classes=num_context)\n",
    "val_job=to_categorical(val_data['job_id'], num_classes=num_job)\n",
    "val_subj=to_categorical(val_data['subject_id'], num_classes=num_sub)\n",
    "# val_speaker=to_categorical(val_data['speaker_id'], num_classes=num_speaker)\n",
    "\n",
    "\n",
    "# ## put all metadata of train data together in one stack\n",
    "# x_val_metadata=np.hstack(val_party, val_state, val_job, val_subj, val_speaker, val_cont)\n",
    "x_val_metadata=np.hstack((val_party, val_state, val_cont,val_job, val_subj, ))\n",
    "\n",
    "# #********************************************************************************#\n",
    "te_party=to_categorical(test_data['party_id'], num_classes=num_party)\n",
    "te_state=to_categorical(test_data['state_id'], num_classes=num_state)\n",
    "te_cont=to_categorical(test_data['context_id'], num_classes=num_context)\n",
    "te_job=to_categorical(test_data['job_id'], num_classes=num_job)\n",
    "te_subj=to_categorical(test_data['subject_id'], num_classes=num_sub)\n",
    "# te_speaker=to_categorical(test_data['speaker_id'], num_classes=num_speaker)\n",
    "\n",
    "# ## put all metadata of train data together in one stack\n",
    "x_test_metadata=np.hstack((te_party, te_state, te_cont,te_job, te_subj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to initialize model weight\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_arr = []\n",
    "statement_input = Input(shape=(num_steps,), dtype='int32', name='main_input')\n",
    "embed_sequences = Embedding(vocab_length+1,embedding_dims,weights=[embedding_weights],input_length=num_steps,trainable=False)(statement_input) #Preloaded glove embeddings\n",
    "# x = Embedding(output_dim=hidden_size, input_dim=vocab_length+1, input_length=num_steps)(statement_input) #Train embeddings from scratch\n",
    "\n",
    "for kernel in kernel_sizes:\n",
    "    x_1 = Conv1D(filters=filter_size,kernel_size=kernel, \n",
    "                 padding=\"same\", activation=\"relu\", strides=1)(embed_sequences)\n",
    "    x_1 = MaxPool1D(3)(x_1)\n",
    "    x_flat = Flatten()(x_1)\n",
    "    x_drop = Dropout(0.7)(x_flat)\n",
    "    kernel_arr.append(x_drop)\n",
    "\n",
    "conv_in = keras.layers.concatenate(kernel_arr)\n",
    "conv_in = Dropout(0.85)(conv_in)\n",
    "conv_in = Dense(128, activation='relu')(conv_in)\n",
    "\n",
    "#Meta input\n",
    "meta_input = Input(shape=(x_train_metadata.shape[1],), name='aux_input')\n",
    "x_drop = Dropout(0.7)(meta_input)\n",
    "x_meta = Dense(100, activation='relu')(x_drop)\n",
    "x = keras.layers.concatenate([conv_in, x_meta])\n",
    "\n",
    "main_output = Dense(6, activation='softmax', name='main_output')(x)\n",
    "model = Model(inputs=[statement_input, meta_input], outputs=[main_output])\n",
    "\n",
    "#************************************************************************#\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.2)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tb = TensorBoard()\n",
    "csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "filepath= \"weights.best.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                             monitor='val_categorical_accuracy', \n",
    "                                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history= model.fit({'main_input': x_train, 'aux_input': x_train_metadata},\n",
    "                   {'main_output': y_train},epochs=30, batch_size=100,\n",
    "                   validation_data=({'main_input': x_val, 'aux_input': x_val_metadata},{'main_output': y_val}),\n",
    "                  callbacks=[tb,csv_logger,checkpoint, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_curve=plt.figure()\n",
    "plt.plot(history.history['categorical_accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Accuracy',fontsize=12)\n",
    "plt.title('Accuracy Curves : CNN',fontsize=12)\n",
    "# accu_curve.savefig('accuracy_cnn_improved_v1.2.png')\n",
    "plt.show()\n",
    "##^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^##\n",
    "loss_curve = plt.figure()\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Loss',fontsize=12)\n",
    "plt.title('Loss Curves :CNN',fontsize=12)\n",
    "# loss_curve.savefig('loss_cnn_improved_v1.2.png')\n",
    "loss_curve.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use multi-convolutional CNN model for fake news classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do small modification on above CNN model, in this notebook I introduce multi convolutional CNN model for fake news classification. let's see how it works and see where is significancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_input = Input(shape=(num_steps,), dtype='int64', name='main_input')\n",
    "embed_sequence = Embedding(vocab_length+1,embedding_dims,weights=[embedding_weights],input_length=num_steps,trainable=False)(statement_input) #Preloaded glove embeddings\n",
    "\n",
    "## add multi convolutional layer\n",
    "l_conv1 = Conv1D(128,3,activation=\"relu\", padding=\"same\", strides=1)(embed_sequence)\n",
    "l_pool1 = MaxPooling1D(3)(l_conv1)\n",
    "l_conv2 = Conv1D(128, 3, activation=\"relu\")(l_pool1)\n",
    "l_pool2 = MaxPooling1D(3)(l_conv2)\n",
    "# l_conv3 = Conv1D(128,3,activation=\"relu\")(l_pool2)\n",
    "# l_pool3 = MaxPool1D(3)(l_conv3)\n",
    "l_flat = Flatten()(l_pool2)\n",
    "conv_in = Dropout(0.9)(l_flat)\n",
    "conv_in = Dense(hidden_size, activation='relu')(conv_in)\n",
    "\n",
    "#Meta input\n",
    "meta_input = Input(shape=(x_train_metadata.shape[1],), name='aux_input')\n",
    "x_meta = Dense(64, activation='relu')(meta_input)\n",
    "x = keras.layers.concatenate([conv_in, x_meta])\n",
    "\n",
    "main_output = Dense(6, activation='softmax', name='main_output')(x)\n",
    "model_multi = Model(inputs=[statement_input, meta_input], outputs=[main_output])\n",
    "\n",
    "#************************************************************************#\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.2)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_multi.compile(optimizer=sgd,\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['categorical_accuracy'])\n",
    "\n",
    "model_multi.summary()\n",
    "\n",
    "tb = TensorBoard()\n",
    "csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "filepath= \"weights.best.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                             monitor='val_categorical_accuracy', \n",
    "                                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history22= model_multi.fit({'main_input': x_train, 'aux_input': x_train_metadata},\n",
    "                           {'main_output': y_train},epochs=15, batch_size=100,\n",
    "                           validation_data=({'main_input': x_val, 'aux_input': x_val_metadata},{'main_output': y_val}),\n",
    "                           callbacks=[tb,csv_logger,checkpoint, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to see performance difference\n",
    "accu_curve=plt.figure()\n",
    "plt.plot(history22.history['categorical_accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history22.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Accuracy',fontsize=12)\n",
    "plt.title('Accuracy Curves : CNN_multi',fontsize=12)\n",
    "# accu_curve.savefig('accuracy_multi_conv_cnn.png')\n",
    "plt.show()\n",
    "##^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^##\n",
    "loss_curve = plt.figure()\n",
    "plt.plot(history22.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history22.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Loss',fontsize=12)\n",
    "plt.title('Loss Curves :CNN Multi',fontsize=12)\n",
    "# loss_curve.savefig('loss_multi_conv_cnn.png')\n",
    "loss_curve.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we run the model multiple times (Experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_arr = []\n",
    "statement_input = Input(shape=(num_steps,), dtype='int32', name='main_input')\n",
    "embed_sequences = Embedding(vocab_length+1,embedding_dims,weights=[embedding_weights],input_length=num_steps,trainable=False)(statement_input) #Preloaded glove embeddings\n",
    "# x = Embedding(output_dim=hidden_size, input_dim=vocab_length+1, input_length=num_steps)(statement_input) #Train embeddings from scratch\n",
    "\n",
    "# for kernel in kernel_sizes:\n",
    "#     x_1 = Conv1D(filters=filter_size,kernel_size=kernel, \n",
    "#                  padding=\"same\", activation=\"relu\", strides=1)(embed_sequences)\n",
    "#     x_1 = MaxPool1D(3)(x_1)\n",
    "#     x_flat = Flatten()(x_1)\n",
    "#     x_drop = Dropout(0.6)(x_flat)\n",
    "#     kernel_arr.append(x_drop)\n",
    "\n",
    "# conv_in = keras.layers.concatenate(kernel_arr)\n",
    "# conv_in = Dropout(0.7)(conv_in)\n",
    "# conv_in = Dense(128, activation='relu')(conv_in)\n",
    "\n",
    "# #Meta input\n",
    "# meta_input = Input(shape=(x_train_metadata.shape[1],), name='aux_input')\n",
    "# x_drop = Dropout(0.7)(meta_input)\n",
    "# x_meta = Dense(100, activation='relu')(x_drop)\n",
    "# x = keras.layers.concatenate([conv_in, x_meta])\n",
    "\n",
    "# main_output = Dense(6, activation='softmax', name='main_output')(x)\n",
    "# model = Model(inputs=[statement_input, meta_input], outputs=[main_output])\n",
    "\n",
    "## add multi convolutional layer\n",
    "l_conv1 = Conv1D(128,3,activation=\"relu\", padding=\"same\", strides=1)(embed_sequences)\n",
    "l_pool1 = MaxPooling1D(3)(l_conv1)\n",
    "l_conv2 = Conv1D(128, 3, activation=\"relu\")(l_pool1)\n",
    "l_pool2 = MaxPooling1D(3)(l_conv2)\n",
    "# l_conv3 = Conv1D(128,3,activation=\"relu\")(l_pool2)\n",
    "# l_pool3 = MaxPool1D(3)(l_conv3)\n",
    "l_flat = Flatten()(l_pool2)\n",
    "conv_in = Dropout(0.9)(l_flat)\n",
    "conv_in = Dense(hidden_size, activation='relu')(conv_in)\n",
    "\n",
    "#Meta input\n",
    "meta_input = Input(shape=(x_train_metadata.shape[1],), name='aux_input')\n",
    "x_drop = Dropout(0.8)(meta_input)\n",
    "x_meta = Dense(64, activation='relu')(x_drop)\n",
    "x = keras.layers.concatenate([conv_in, x_meta])\n",
    "\n",
    "main_output = Dense(6, activation='softmax', name='main_output')(x)\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "####\n",
    "runs=5\n",
    "histArr = []\n",
    "\n",
    "for i in range(runs):\n",
    "    print('Running iteration %i/%i' % (i+1, runs))\n",
    "    model_multirun = Model(inputs=[statement_input, meta_input], outputs=[main_output])\n",
    "    model_multirun.compile(optimizer=sgd,\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['categorical_accuracy'])\n",
    "    \n",
    "    ####\n",
    "    tb = TensorBoard()\n",
    "    csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "    #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "    #filepath= \"weights.best.hdf5\"\n",
    "    # checkpoint = keras.callbacks.ModelCheckpoint(filepath, \n",
    "    #                                              monitor='val_categorical_accuracy', \n",
    "    #                                              verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    history22= model_multirun.fit({'main_input': x_train, 'aux_input': x_train_metadata},\n",
    "                                  {'main_output': y_train},epochs=30, batch_size=100, verbose=1,\n",
    "                                  validation_data=({'main_input': x_val, 'aux_input': x_val_metadata},{'main_output': y_val}),\n",
    "                                  callbacks=[keras.callbacks.ModelCheckpoint('model-%i.h5'%(i+1), \n",
    "                                                                              monitor='val_categorical_accuracy', verbose=1, \n",
    "                                                                              save_best_only=True, mode='max'), tb, csv_logger])\n",
    "                       #callbacks=[tb,csv_logger,checkpoint, es])\n",
    "    print()\n",
    "    histArr.append(history22.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the output\n",
    "with open('history22.pkl', 'wb') as f:\n",
    "    cPickle.dump(histArr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histArr = cPickle.load(open('history22.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg(histArr, his_key):\n",
    "    tmp = []\n",
    "    for history in histArr:\n",
    "        tmp.append(history[his_key][np.argmin(history['val_loss'])])\n",
    "    return np.mean(tmp)\n",
    "    \n",
    "print('Training: \\t%0.4f loss / %0.4f acc' % (get_avg(histArr, 'loss'),\n",
    "                                              get_avg(histArr, 'categorical_accuracy')))\n",
    "print('Validation: \\t%0.4f loss / %0.4f acc' % (get_avg(histArr, 'val_loss'),\n",
    "                                                get_avg(histArr, 'val_categorical_accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(title, histArr, key_acc, key_loss):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    # Accuracy\n",
    "    ax1.set_title('Model accuracy (%s)' % title)\n",
    "    names = []\n",
    "    for i, model in enumerate(histArr):\n",
    "        ax1.plot(model[key_acc])\n",
    "        ax1.set_xlabel('epoch')\n",
    "        names.append('Model %i' % (i+1))\n",
    "        ax1.set_ylabel('accuracy')\n",
    "    ax1.legend(names, loc='lower right')\n",
    "    # Loss\n",
    "    ax2.set_title('Model loss (%s)' % title)\n",
    "    for model in histArr:\n",
    "        ax2.plot(model[key_loss])\n",
    "        ax2.set_xlabel('epoch')\n",
    "        ax2.set_ylabel('loss')\n",
    "    ax2.legend(names, loc='upper right')\n",
    "    fig.set_size_inches(20, 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss('training', histArr, 'categorical_accuracy', 'loss')\n",
    "plot_acc_loss('validation', histArr, 'val_categorical_accuracy', 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make prediction\n",
    "from keras.models import load_model\n",
    "#Load a pre-trained model if any\n",
    "model1 = load_model('weights.best.hdf5')\n",
    "preds = model1.predict([x_test,x_test_metadata], batch_size=batch_size, verbose=1)\n",
    "print(np.array(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils.np_utils import accuracy\n",
    "# acc = accuracy(y_test, np.round(np.array(preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  C-LSTM model for fake news classification\n",
    "\n",
    "To better understand performance gap between different convolutional models, here I want to see Convolutional -LSTM model for fake news classification. Note that I didn't run multiple convolutional filers for fake news texts because it raise strange error, so I'll proceed somehow simple but powerful model for fake news classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## C-LSTM model implementation (trail version)\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "\n",
    "statement_input = Input(shape=(num_steps,), dtype='int64', name='main_input')\n",
    "# embed_layer = Embedding(output_dim=hidden_size, input_dim=vocab_length+1, input_length=num_steps)(statement_input) #Train embeddings from scratch\n",
    "embed_layer = Embedding(vocab_length+1,embedding_dims,weights=[embedding_weights],input_length=num_steps,trainable=False)(statement_input) #Preloaded glove embeddings\n",
    "l_lstm = Bidirectional(LSTM(100, return_sequences=True, dropout=0.25, recurrent_dropout=0.1))(embed_layer)\n",
    "# lstm_pool = GlobalMaxPool1D()(l_lstm)\n",
    "\n",
    "## let's add convolutional layer on it\n",
    "l_conv1 = Conv1D(128, 3, activation=\"relu\")(l_lstm)\n",
    "l_pool1 = MaxPooling1D(3)(l_conv1)\n",
    "l_conv2 = Conv1D(128,3,activation=\"relu\")(l_pool1)\n",
    "l_pool2 = MaxPool1D(3)(l_conv2)\n",
    "l_flat = Flatten()(l_pool2)\n",
    "l_drop = Dropout(0.8)(l_flat)\n",
    "conv_in = Dense(hidden_size, activation=\"relu\")(l_drop)\n",
    "\n",
    "### metadata\n",
    "meta_input = Input(shape=(x_train_metadata.shape[1],), name='aux_input')\n",
    "x_meta_hidden = Dense(64, activation='relu')(meta_input)\n",
    "x_meta_reg = Dropout(0.6)(x_meta_hidden)\n",
    "\n",
    "conv_final = keras.layers.concatenate([conv_in, x_meta_reg])\n",
    "model_output = Dense(6, activation='softmax', name='main_output')(conv_final)\n",
    "model_CLSTM = Model(inputs=[statement_input, meta_input], outputs=[model_output])\n",
    "\n",
    "## compile model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_CLSTM.compile(optimizer=sgd,\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['categorical_accuracy'])\n",
    "\n",
    "model_CLSTM.summary()\n",
    "\n",
    "tb = TensorBoard()\n",
    "csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "filepath= \"weights.best.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                             monitor='val_categorical_accuracy', \n",
    "                                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history_clstm = model_CLSTM.fit({'main_input': x_train, 'aux_input': x_train_metadata},\n",
    "                                {'main_output': y_train},epochs=num_epochs, batch_size=batch_size,\n",
    "                                validation_data=({'main_input': x_val, 'aux_input': x_val_metadata},{'main_output': y_val}),\n",
    "                                callbacks=[tb,csv_logger,checkpoint, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experimental modification on c-lstm model for fake news classification\n",
    "\n",
    "\"\"\"\n",
    "## let's add lstm\n",
    "l_lstm = Bidirectional(LSTM(100, return_sequences=True, dropout=0.25, recurrent_dropout=0.1))(embed_layer)\n",
    "lstm_pool = GlobalMaxPool1D()(l_lstm)\n",
    "lstm_drop = Dropout(0.6)(lstm_pool)\n",
    "lstm_dense = Dense(hidden_size, activation=\"relu\")(lstm_drop)\n",
    "\n",
    "## let's add convolutional layer\n",
    "l_conv1 = Conv1D(128, 3, activation=\"relu\")(embed_layer)\n",
    "l_pool1 = MaxPooling1D(3)(l_conv1)\n",
    "l_conv2 = Conv1D(128,3,activation=\"relu\")(l_pool1)\n",
    "l_pool2 = MaxPool1D(3)(l_conv2)\n",
    "l_flat = Flatten()(l_pool2)\n",
    "l_drop = Dropout(0.6)(l_flat)\n",
    "conv_in = Dense(hidden_size, activation=\"relu\")(l_drop)\n",
    "\n",
    "## merge lstm and convs\n",
    "conv_ins = keras.layers.concatenate([conv_in, lstm_dense])\n",
    "\n",
    "### metadata\n",
    "meta_input = Input(shape=(x_train_metadata.shape[1],), name='aux_input')\n",
    "x_meta_hidden = Dense(64, activation='relu')(meta_input)\n",
    "x_meta_reg = Dropout(0.6)(x_meta_hidden)\n",
    "\n",
    "conv_final = keras.layers.concatenate([conv_ins, x_meta_reg])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize c-lstm model output\n",
    "accu_curve=plt.figure()\n",
    "plt.plot(history_clstm.history['categorical_accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history_clstm.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Accuracy',fontsize=12)\n",
    "plt.title('Accuracy Curves : C-LSTM',fontsize=12)\n",
    "accu_curve.savefig('accuracy_clstm_improved_v1.4.4.png')\n",
    "plt.show()\n",
    "##^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^##\n",
    "loss_curve = plt.figure()\n",
    "plt.plot(history_clstm.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history_clstm.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Loss',fontsize=12)\n",
    "plt.title('Loss Curves :C-LSTM',fontsize=12)\n",
    "loss_curve.savefig('loss_clstm_improved_v1.4.4.png')\n",
    "loss_curve.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvised version of C-LSTM model for fake news classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 64, 300)      3722700     main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 64, 256)      439296      embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 63, 3)        1539        bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 62, 3)        2307        bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 60, 3)        3843        bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 58, 3)        5379        bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 15, 3)        0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 15, 3)        0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 15, 3)        0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 14, 3)        0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 45)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 45)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 45)           0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 42)           0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 45)           0           flatten_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 45)           0           flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 45)           0           flatten_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 42)           0           flatten_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 177)          0           dropout_37[0][0]                 \n",
      "                                                                 dropout_38[0][0]                 \n",
      "                                                                 dropout_39[0][0]                 \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          (None, 94)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 177)          0           concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 94)           0           aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          22784       dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 64)           6080        dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 192)          0           dense_30[0][0]                   \n",
      "                                                                 dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 6)            1158        concatenate_23[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,205,086\n",
      "Trainable params: 482,386\n",
      "Non-trainable params: 3,722,700\n",
      "__________________________________________________________________________________________________\n",
      "Train on 10240 samples, validate on 1284 samples\n",
      "Epoch 1/30\n",
      "10240/10240 [==============================] - 81s 8ms/step - loss: 1.7815 - categorical_accuracy: 0.1940 - val_loss: 1.7596 - val_categorical_accuracy: 0.2040\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.20405, saving model to weights.best.hdf5\n",
      "Epoch 2/30\n",
      "10240/10240 [==============================] - 84s 8ms/step - loss: 1.7603 - categorical_accuracy: 0.2017 - val_loss: 1.7514 - val_categorical_accuracy: 0.2188\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.20405 to 0.21885, saving model to weights.best.hdf5\n",
      "Epoch 3/30\n",
      "10240/10240 [==============================] - 86s 8ms/step - loss: 1.7547 - categorical_accuracy: 0.2091 - val_loss: 1.7483 - val_categorical_accuracy: 0.2352\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.21885 to 0.23520, saving model to weights.best.hdf5\n",
      "Epoch 4/30\n",
      "10240/10240 [==============================] - 87s 8ms/step - loss: 1.7500 - categorical_accuracy: 0.2130 - val_loss: 1.7434 - val_categorical_accuracy: 0.2266\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.23520\n",
      "Epoch 5/30\n",
      "10240/10240 [==============================] - 85s 8ms/step - loss: 1.7511 - categorical_accuracy: 0.2132 - val_loss: 1.7405 - val_categorical_accuracy: 0.2298\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.23520\n",
      "Epoch 6/30\n",
      "10240/10240 [==============================] - 85s 8ms/step - loss: 1.7476 - categorical_accuracy: 0.2159 - val_loss: 1.7397 - val_categorical_accuracy: 0.2259\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.23520\n",
      "Epoch 7/30\n",
      "10240/10240 [==============================] - 85s 8ms/step - loss: 1.7419 - categorical_accuracy: 0.2231 - val_loss: 1.7386 - val_categorical_accuracy: 0.2352\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.23520\n",
      "Epoch 8/30\n",
      "10240/10240 [==============================] - 84s 8ms/step - loss: 1.7410 - categorical_accuracy: 0.2245 - val_loss: 1.7382 - val_categorical_accuracy: 0.2438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.23520 to 0.24377, saving model to weights.best.hdf5\n",
      "Epoch 9/30\n",
      "10240/10240 [==============================] - 85s 8ms/step - loss: 1.7451 - categorical_accuracy: 0.2158 - val_loss: 1.7386 - val_categorical_accuracy: 0.2352\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.24377\n",
      "Epoch 10/30\n",
      "10240/10240 [==============================] - 85s 8ms/step - loss: 1.7401 - categorical_accuracy: 0.2287 - val_loss: 1.7349 - val_categorical_accuracy: 0.2453\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.24377 to 0.24533, saving model to weights.best.hdf5\n",
      "Epoch 11/30\n",
      "10240/10240 [==============================] - 84s 8ms/step - loss: 1.7402 - categorical_accuracy: 0.2214 - val_loss: 1.7332 - val_categorical_accuracy: 0.2445\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.24533\n",
      "Epoch 12/30\n",
      "10240/10240 [==============================] - 85s 8ms/step - loss: 1.7386 - categorical_accuracy: 0.2298 - val_loss: 1.7311 - val_categorical_accuracy: 0.2407\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.24533\n",
      "Epoch 13/30\n",
      "10240/10240 [==============================] - 85s 8ms/step - loss: 1.7393 - categorical_accuracy: 0.2278 - val_loss: 1.7336 - val_categorical_accuracy: 0.2445\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.24533\n",
      "Epoch 14/30\n",
      "10240/10240 [==============================] - 85s 8ms/step - loss: 1.7353 - categorical_accuracy: 0.2312 - val_loss: 1.7312 - val_categorical_accuracy: 0.2453\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.24533\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "\n",
    "##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++##\n",
    "kernel_arr = []\n",
    "statement_input = Input(shape=(num_steps,), dtype='int32', name='main_input')\n",
    "embedded_sequences = Embedding(vocab_length+1,embedding_dims,weights=[embedding_weights],input_length=num_steps,trainable=False)(statement_input) #Preloaded glove embeddings\n",
    "# x = Embedding(output_dim=hidden_size, input_dim=vocab_length+1, input_length=num_steps)(statement_input) #Train embeddings from scratch\n",
    "x_lstm = Bidirectional(LSTM(128, return_sequences=True, dropout=0.4, recurrent_dropout=0.5))(embedded_sequences)\n",
    "\n",
    "for kernel in kernel_sizes:\n",
    "    x_1 = Conv1D(filters=filter_size,kernel_size=kernel, \n",
    "                 padding=\"valid\", activation=\"relu\", strides=1)(x_lstm)\n",
    "    x_pool = MaxPool1D(4)(x_1)\n",
    "    #x_pool = GlobalMaxPool1D()(x_1)\n",
    "    x_flat = Flatten()(x_pool)\n",
    "    x_drop = Dropout(0.7)(x_flat)\n",
    "    kernel_arr.append(x_drop)\n",
    "\n",
    "conv_in = keras.layers.concatenate(kernel_arr)\n",
    "conv_in = Dropout(0.7)(conv_in)\n",
    "conv_in = Dense(128, activation='relu')(conv_in)\n",
    "\n",
    "\"\"\"\n",
    "## use bidirectional lstm\n",
    "x_lstm = Bidirectional(LSTM(100, return_sequences=True, dropout=0.25, recurrent_dropout=0.1))(x_1)\n",
    "lstm_pool = GlobalMaxPool1D()(x_lstm)\n",
    "lstm_dense = Dense(100, activation=\"relu\")(lstm_pool)\n",
    "\n",
    "## first concatenate\n",
    "conv_ins= keras.layers.concatenate([conv_in, lstm_dense])\n",
    "\"\"\"\n",
    "\n",
    "#Meta input\n",
    "meta_input = Input(shape=(x_train_metadata.shape[1],), name='aux_input')\n",
    "x_drop = Dropout(0.7)(meta_input)\n",
    "x_meta = Dense(64, activation='relu')(x_drop)\n",
    "x = keras.layers.concatenate([conv_in,x_meta])\n",
    "\n",
    "main_output = Dense(6, activation='softmax', name='main_output')(x)\n",
    "model_clstm_ = Model(inputs=[statement_input, meta_input], outputs=[main_output])\n",
    "\n",
    "\n",
    "## compile model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_clstm_.compile(optimizer=sgd,\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['categorical_accuracy'])\n",
    "\n",
    "\n",
    "model_clstm_.summary()\n",
    "\n",
    "##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++##\n",
    "tb = TensorBoard()\n",
    "csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "filepath= \"weights.best.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                             monitor='val_categorical_accuracy', \n",
    "                                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "history_clstm_ = model_clstm_.fit({'main_input': x_train, 'aux_input': x_train_metadata},\n",
    "                                {'main_output': y_train},epochs=num_epochs, batch_size=batch_size,\n",
    "                                validation_data=({'main_input': x_val, 'aux_input': x_val_metadata},{'main_output': y_val}),\n",
    "                                callbacks=[tb,csv_logger,checkpoint, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### visualize c-lstm model output\n",
    "accu_curve=plt.figure()\n",
    "plt.plot(history_clstm_.history['categorical_accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(history_clstm_.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Accuracy',fontsize=12)\n",
    "plt.title('Accuracy Curves : C-LSTM',fontsize=12)\n",
    "# accu_curve.savefig('accuracy_clstm_improved_v1.4.4.png')\n",
    "plt.show()\n",
    "##^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^##\n",
    "loss_curve = plt.figure()\n",
    "plt.plot(history_clstm_.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history_clstm_.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=12)\n",
    "plt.xlabel('Epochs ',fontsize=12)\n",
    "plt.ylabel('Loss',fontsize=12)\n",
    "plt.title('Loss Curves :C-LSTM',fontsize=12)\n",
    "# loss_curve.savefig('loss_clstm_improved_v1.4.4.png')\n",
    "loss_curve.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character level CNN model for fake news classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from math import sqrt\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras import Model\n",
    "from keras.layers import Input, Dense, Concatenate, Embedding, Flatten\n",
    "from keras.layers import AlphaDropout\n",
    "from keras.layers import ThresholdedReLU\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "import keras as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### character level classification (simple version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers=[[256, 7, 3],\n",
    "             [256, 7, 3],\n",
    "             [256, 3, -1],\n",
    "             [256, 3, -1],\n",
    "             [256, 3, -1],\n",
    "             [256, 3, 3]]\n",
    "\n",
    "fully_connected_layers=[1024, 1024]\n",
    "dropout_p=0.5\n",
    "threshold=1e-06\n",
    "input_size=70\n",
    "alphabet='abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:\\'\"/\\\\|_@#$%^&*~`+-=<>()[]{}'\n",
    "\n",
    "batch_size=128\n",
    "checkpoint_every=70\n",
    "epochs=5000\n",
    "# evaluate_every=100\n",
    "batch_size=128\n",
    "checkpoint_every=100\n",
    "epochs=5000\n",
    "# evaluate_every=100\n",
    "embedding_size=128\n",
    "alphabet_size=69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## define model input, create embedding layer\n",
    "sent_inputs = Input(shape=(input_size,), name='sent_input', dtype='int64')  # shape=(?, 1014)\n",
    "\n",
    "conv = Embedding(alphabet_size+1, embedding_size, input_length=input_size, trainable=False)(sent_inputs)\n",
    "# Conv \n",
    "conv_lay=[]\n",
    "for filter_num, filter_size, pooling_size in conv_layers:\n",
    "    x_conv = Conv1D(filter_num, filter_size, padding=\"same\")(conv) \n",
    "    x_pool  = GlobalMaxPooling1D()(x_conv)\n",
    "    x_drop = Dropout(0.6)(x_pool)\n",
    "    conv_lay.append(x_drop)\n",
    "#     if pooling_size != -1:\n",
    "#         conv = MaxPooling1D(pool_size=pooling_size)(conv) # Final shape=(None, 34, 256)\n",
    "\n",
    "# x = Flatten()(conv_lay) # (None, 8704)\n",
    "x=concatenate(conv_lay)\n",
    "\n",
    "# Fully connected layers \n",
    "for dense_size in fully_connected_layers:\n",
    "    x = Dense(dense_size, activation='relu')(x) # dense_size == 1024\n",
    "    x = Dropout(dropout_p)(x)\n",
    "    \n",
    "model_output = Dense(6, activation='softmax')(x)\n",
    "# Build model\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.2)\n",
    "\n",
    "model_char = Model(inputs=sent_inputs, outputs=model_output)\n",
    "model_char.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "\n",
    "model_char.summary()\n",
    "tb = TensorBoard()\n",
    "csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "es=EarlyStopping(monitor=\"val_loss\", mode='min', verbose=1, patience=3 )\n",
    "filepath= \"weights.best.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                             monitor='val_categorical_accuracy', \n",
    "                                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "# history_char= model_char.fit(x_train,y_train,epochs=num_epochs, batch_size=batch_size,\n",
    "#                                validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_char.fit(x_train,y_train,epochs=10, batch_size=64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Recurrent CNN model for fake news classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import string\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', limit= 500000,binary=True)\n",
    "embeddings = np.zeros((word2vec.syn0.shape[0] + 1, word2vec.syn0.shape[1]), dtype = \"float32\")\n",
    "embeddings[:word2vec.syn0.shape[0]] = word2vec.syn0\n",
    "\n",
    "MAX_TOKENS = word2vec.syn0.shape[0]\n",
    "embedding_dim = word2vec.syn0.shape[1]\n",
    "hidden_dim_1 = 200\n",
    "hidden_dim_2 = 100\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "document = Input(shape = (None, ), dtype = \"int32\")\n",
    "left_context = Input(shape = (None, ), dtype = \"int32\")\n",
    "right_context = Input(shape = (None, ), dtype = \"int32\")\n",
    "\n",
    "embedder = Embedding(MAX_TOKENS + 1, embedding_dim, weights = [embeddings], trainable = False)\n",
    "doc_embedding = embedder(document)\n",
    "l_embedding = embedder(left_context)\n",
    "r_embedding = embedder(right_context)\n",
    "\n",
    "forward = LSTM(hidden_dim_1, return_sequences = True)(l_embedding)\n",
    "backward = LSTM(hidden_dim_1, return_sequences = True, go_backwards = True)(r_embedding)\n",
    "\n",
    "# Keras returns the output sequences in reverse order.\n",
    "backward = Lambda(lambda x: K.reverse(x, axes = 1))(backward)\n",
    "together = concatenate([forward, doc_embedding, backward], axis = 2)\n",
    "\n",
    "semantic = Conv1D(hidden_dim_2, kernel_size = 1, activation = \"tanh\")(together)\n",
    "\n",
    "## define customized maxpooling layer\n",
    "pool_rnn = Lambda(lambda x: K.max(x, axis = 1), output_shape = (hidden_dim_2, ))(semantic)\n",
    "model_output = Dense(NUM_CLASSES, input_dim = hidden_dim_2, activation = \"softmax\")(pool_rnn)\n",
    "\n",
    "model_RCNN = Model(inputs = [document, left_context, right_context], outputs = model_output)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_RCNN.compile(optimizer=sgd,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "\n",
    "model_RCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tb = TensorBoard()\n",
    "# csv_logger = keras.callbacks.CSVLogger('training.log')\n",
    "# filepath= \"weights.best.hdf5\"\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(filepath, \n",
    "#                                              monitor='val_categorical_accuracy', \n",
    "#                                              verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# history_rcnn= RCNN_model.fit({'main_input': x_train, 'aux_input': x_train_metadata},\n",
    "#                              {'main_output': y_train},epochs=num_epochs, batch_size=batch_size,\n",
    "#                              validation_data=({'main_input': x_val, 'aux_input': x_val_metadata},{'main_output': y_val}),\n",
    "#                              callbacks=[tb,csv_logger,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is some example text.\"\n",
    "text = text.strip().lower().translate(str.maketrans({key: \" {0} \".format(key) for key in string.punctuation}))\n",
    "tokens = text.split()\n",
    "# tokens = [voca[token].index if token in word2vec.vocab else MAX_TOKENS for token in tokens]\n",
    "\n",
    "doc_as_array = np.array([tokens])\n",
    "# We shift the document to the right to obtain the left-side contexts.\n",
    "left_context_as_array = np.array([[MAX_TOKENS] + tokens[:-1]])\n",
    "# We shift the document to the left to obtain the right-side contexts.\n",
    "right_context_as_array = np.array([tokens[1:] + [MAX_TOKENS]])\n",
    "\n",
    "target = np.array([NUM_CLASSES * [0]])\n",
    "target[0][3] = 1\n",
    "\n",
    "history33 = model_RCNN.fit([doc_as_array, left_context_as_array, right_context_as_array], target, epochs = 1, verbose = 0)\n",
    "loss = history33.history[\"loss\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
